---
title: "second post"
date: 2017-10-22T20:35:21+02:00
draft: true
tags: ["linear algebra", "18.06", "matrices"]
---

One of the most crucial changes in my viewpoint came when I learned that matrices, much like functions, _act_ on inputs. Until then, a matrix was just a collection of numbers and matrix multiplication was just a mechanical set of rules used to produce another collection of numbers. I knew that the result of matrix multiplication could be a scalar, a vector or another matrix... but I abandoned any further investigations.

I'm going to assume that the reader is familiar with the mechanics of matrix multiplication. What I'll be talking about is how a matrix affects a vector; in this case, how a matrix transforms a vector into a different vector and that the transformation is encoded in the matrix itself.

An example Prof. Strang uses in his lectures and book is the _difference matrix_. It looks like this:

 \begin{bmatrix}
  1 & 0 & 0 \newline
  -1 & 1 & 0 \newline
  0 & -1 & 1
 \end{bmatrix}

Now, let's say we have a vector $$ \begin{bmatrix} x_1 \newline x_2 \newline x_3 \end{bmatrix} \in  \mathbb{R}^3$$


Here's sum inline math: {{< tex "\sum_{n=1}^{\infty} 2^{-n} = 1" >}}.

